# Retrospective Interview Questions

## Q1: Timeline Accuracy

Was the timeline estimate accurate?
- **[E] - Excellent**, within ±20%
- **[G] - Good**, ±20-50% variance
- **[P] - Poor**, >50% variance

**If [P], ask follow-up:**
Why was it poor?
- **[U]** - Underestimated complexity
- **[O]** - Overestimated resources (Speed Multiplier too high)
- **[B]** - Unexpected blockers
- **[S]** - Scope creep
- **[X]** - Other (specify)

---

## Q2: Complexity Assessment

Was the complexity score accurate?
[Original: {X}/10 → Actual: {Y}/10]

If different, what changed? (free text)

---

## Q3: Speed Multiplier Validation

Was the Speed Multiplier realistic?
[Assumed: {X}x → Actual: {Y}x]

**If lower than expected:**
- LLM less effective than assumed? (which areas?)
- More manual work required? (what tasks?)
- Learning curve steeper? (which technologies?)

**If higher than expected:**
- LLM more effective? (which tasks automated well?)
- Better tools discovered? (which ones?)
- Existing knowledge leveraged? (what areas?)

(free text)

---

## Q4: What Went Well

List 2-5 things that worked:
- Technical decisions
- Tools/approaches
- Correct assumptions
- Unexpected wins

(free text, one per line)

---

## Q5: What Could Improve

List 2-5 things to improve:
- Overestimated areas
- Underestimated areas
- Foreseen blockers
- Better approaches discovered

(free text, one per line)

---

## Q6: Recommendations for Future Similar Ideas

Based on this experience:
- Adjust Speed Multiplier: {X}x → {Y}x for {domain}
- Adjust complexity scoring: Add {factor} consideration
- Common pitfalls: Watch out for {issue}
- Suggested approach: Use {tool/pattern} from start

(free text, structured recommendations)
